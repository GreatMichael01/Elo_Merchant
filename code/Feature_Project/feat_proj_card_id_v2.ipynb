{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import log_loss\n",
    "import lightgbm as lgb\n",
    "from sklearn import preprocessing\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Simple processing train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../../data/train.csv', parse_dates=[\"first_active_month\"])\n",
    "test = pd.read_csv('../../data/test.csv', parse_dates=[\"first_active_month\"])\n",
    "test[\"target\"] = -9999\n",
    "data = pd.concat([train, test])\n",
    "data[\"month\"] = data[\"first_active_month\"].apply(lambda x: x.month)\n",
    "data[\"day\"] = data[\"first_active_month\"].apply(lambda x: x.day)\n",
    "data[\"dayofyear\"] = data[\"first_active_month\"].apply(lambda x: x.dayofyear)\n",
    "data['week'] = data[\"first_active_month\"].dt.weekofyear\n",
    "data['dayofweek'] = data['first_active_month'].dt.dayofweek\n",
    "data['days'] = (datetime.date(2018, 2, 1) - data['first_active_month'].dt.date).dt.days\n",
    "data[\"quarter\"] = data[\"first_active_month\"].apply(lambda x: x.quarter)\n",
    "data[\"is_month_start\"] = data[\"first_active_month\"].apply(lambda x: x.is_month_start)\n",
    "data[\"days_feature1\"] = data[\"days\"] * data[\"feature_1\"]\n",
    "data[\"days_feature2\"] = data[\"days\"] * data[\"feature_2\"]\n",
    "data[\"days_feature3\"] = data[\"days\"] * data[\"feature_3\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Processing historical and new_transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pro_trans(trans): \n",
    "    \"\"\"\n",
    "    Simple processing historical_transactions and new_transactions and extract features.\n",
    "    \"\"\"\n",
    "    trans[\"authorized_flag\"] = trans[\"authorized_flag\"].map({\"Y\": 1, \"N\": 0})\n",
    "    trans[\"category_1\"] = trans[\"category_1\"].map({\"Y\": 1, \"N\":0})\n",
    "    trans[\"purchase_date\"] = pd.to_datetime(trans[\"purchase_date\"])\n",
    "    trans[\"month\"] = trans[\"purchase_date\"].apply(lambda x: x.month)\n",
    "    trans[\"weekofyear\"] = trans[\"purchase_date\"].apply(lambda x: x.weekofyear)\n",
    "    trans[\"dayofweek\"] = trans[\"purchase_date\"].apply(lambda x: x.dayofweek)\n",
    "    trans[\"weekend\"] = (trans[\"purchase_date\"].apply(lambda x: x.dayofweek) >= 5).astype(int)\n",
    "    trans[\"hour\"] = trans[\"purchase_date\"].apply(lambda x: x.hour)\n",
    "    trans[\"quarter\"] = trans[\"purchase_date\"].apply(lambda x: x.quarter)\n",
    "    trans[\"minute\"] = trans[\"purchase_date\"].apply(lambda x: x.minute)\n",
    "    trans[\"month_diff\"] = ((datetime.datetime.today() - trans[\"purchase_date\"]).apply(lambda x: x.days)) // 30\n",
    "    trans[\"month_diff\"] += trans[\"month_lag\"]\n",
    "    trans[\"month_diff2\"] = trans[\"month\"] - trans[\"month_lag\"]\n",
    "    trans[\"category_2\"] = trans[\"category_2\"].fillna(value = 2.0)\n",
    "    trans[\"category_3\"] = trans[\"category_3\"].fillna(value = \"A\")\n",
    "    trans[\"merchant_id\"] = trans[\"merchant_id\"].fillna(value = \"M_ID_00a6ca8a8a\")\n",
    "    lbl = preprocessing.LabelEncoder()\n",
    "    trans[\"category_3\"] = lbl.fit_transform(list(trans[\"category_3\"].values))\n",
    "    \n",
    "    for col in [\"category_2\", \"category_3\", \"month\", \"hour\"]:\n",
    "        trans[col+\"_pa_mean\"] = trans[\"purchase_amount\"].groupby(trans[col]).agg(\"mean\")\n",
    "        trans[col+\"_pa_max\"] = trans[\"purchase_amount\"].groupby(trans[col]).agg(\"max\")\n",
    "        trans[col+\"_pa_min\"] = trans[\"purchase_amount\"].groupby(trans[col]).agg(\"min\")\n",
    "        trans[col+\"_pa_var\"] = trans[\"purchase_amount\"].groupby(trans[col]).agg(\"var\")\n",
    "        trans[col+\"_im_mean\"] = trans[\"installments\"].groupby(trans[col]).agg(\"mean\")\n",
    "        trans[col+\"_im_max\"] = trans[\"installments\"].groupby(trans[col]).agg(\"max\")\n",
    "        trans[col+\"_im_min\"] = trans[\"installments\"].groupby(trans[col]).agg(\"min\")\n",
    "        trans[col+\"_im_var\"] = trans[\"installments\"].groupby(trans[col]).agg(\"var\")\n",
    "    trans_data = trans\n",
    "    \n",
    "    return trans_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking Reference from Other Kernels\n",
    "def trans_agg(trans, nunique_col, prefix):\n",
    "    agg_func = {\"purchase_date\":[\"max\", \"min\"],\n",
    "                \"month_diff\": [\"max\", \"min\", \"mean\", \"var\"],\n",
    "                \"weekend\": [\"max\", \"min\", \"mean\", \"sum\"],\n",
    "                \"authorized_flag\": [\"max\", \"min\", \"mean\", \"sum\"],\n",
    "                \"category_1\": [\"max\", \"min\", \"mean\", \"sum\"],\n",
    "                \"category_2\": [\"max\", \"min\", \"mean\", \"sum\"],\n",
    "                \"category_3\": [\"max\", \"min\", \"mean\", \"sum\"],\n",
    "                \"installments\": [\"max\", \"min\", \"mean\", \"std\", \"sum\"],\n",
    "                \"purchase_amount\": [\"max\", \"min\", \"mean\", \"std\", \"sum\"],\n",
    "                \"month_lag\": [\"mean\", \"max\", \"min\", \"nunique\", \"var\"],\n",
    "                \"month_diff\": [\"mean\", \"max\", \"min\", \"nunique\", \"var\"],\n",
    "                \"card_id\": [\"size\", \"nunique\"],\n",
    "                \"month\": [\"max\", \"min\", \"nunique\"],\n",
    "                \"hour\": [\"max\", \"min\", \"nunique\"],\n",
    "                \"weekofyear\": [\"max\", \"min\", \"nunique\"],\n",
    "                \"dayofweek\": [\"max\", \"min\", \"nunique\"],\n",
    "                \"merchant_id\": [\"nunique\"],\n",
    "                \"city_id\": [\"nunique\"],\n",
    "                \"state_id\": [\"nunique\"],\n",
    "                \"subsector_id\": [\"max\", \"min\", \"nunique\"],\n",
    "                \"merchant_category_id\": [\"max\", \"min\", \"nunique\"]}\n",
    "    agg_trans = trans.groupby([nunique_col]).agg(agg_func)\n",
    "    agg_trans.columns = [prefix + '_'.join(col).strip() for col in agg_trans.columns.values]\n",
    "    agg_trans.reset_index(inplace=True)\n",
    "    df = (trans.groupby(nunique_col).size().reset_index(name='{}transactions_count'.format(prefix)))\n",
    "    agg_trans = pd.merge(df, agg_trans, on=nunique_col, how='left')\n",
    "    \n",
    "    agg_trans[prefix + \"purchase_date_max\"] = pd.to_datetime(agg_trans[prefix + \"purchase_date_max\"])\n",
    "    agg_trans[prefix + \"purchase_date_min\"] = pd.to_datetime(agg_trans[prefix + \"purchase_date_min\"])\n",
    "    agg_trans[prefix + \"purchase_date_diff\"] = (agg_trans[prefix + \"purchase_date_max\"] - agg_trans[prefix + \"purchase_date_min\"]).dt.days   \n",
    "    agg_trans[prefix + \"purchase_date_average\"] = agg_trans[prefix + \"purchase_date_diff\"] / agg_trans[prefix + \"card_id_size\"]\n",
    "    agg_trans[prefix + \"purchase_date_uptonow\"] = (datetime.datetime.today() - agg_trans[prefix + \"purchase_date_max\"]).dt.days\n",
    "    for feature in [prefix + \"purchase_date_max\", prefix + \"purchase_date_min\"]:\n",
    "        agg_trans[feature] = agg_trans[feature].astype(np.int64) * 1e-9\n",
    "\n",
    "    return agg_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 processing historical_transactions base on card_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data over.\n",
      "Processing trans_agg function...\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-8077ecf075d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mhist_trans_pro\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpro_trans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist_trans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Processing trans_agg function...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mhist_card_trans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrans_agg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist_trans_pro\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnunique_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"card_id\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'hist_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-2489d6c0fad2>\u001b[0m in \u001b[0;36mtrans_agg\u001b[1;34m(trans, nunique_col, prefix)\u001b[0m\n\u001b[0;32m     22\u001b[0m                 \u001b[1;34m\"subsector_id\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"max\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"min\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"nunique\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m                 \"merchant_category_id\": [\"max\", \"min\", \"nunique\"]}\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0magg_trans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnunique_col\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magg_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[0magg_trans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mprefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0magg_trans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0magg_trans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mgroupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, **kwargs)\u001b[0m\n\u001b[0;32m   6657\u001b[0m         return groupby(self, by=by, axis=axis, level=level, as_index=as_index,\n\u001b[0;32m   6658\u001b[0m                        \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroup_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msqueeze\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6659\u001b[1;33m                        observed=observed, **kwargs)\n\u001b[0m\u001b[0;32m   6660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6661\u001b[0m     def asfreq(self, freq, method=None, how=None, normalize=False,\n",
      "\u001b[1;32mD:\\python3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36mgroupby\u001b[1;34m(obj, by, **kwds)\u001b[0m\n\u001b[0;32m   2150\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'invalid type: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2152\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, **kwargs)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNDFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m             \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlevel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   4433\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4435\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4437\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_protect_consolidate\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m   4422\u001b[0m         \"\"\"\n\u001b[0;32m   4423\u001b[0m         \u001b[0mblocks_before\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4424\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4425\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mblocks_before\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4426\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mf\u001b[1;34m()\u001b[0m\n\u001b[0;32m   4431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4432\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4433\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4435\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mconsolidate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   4096\u001b[0m         \u001b[0mbm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4097\u001b[0m         \u001b[0mbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4098\u001b[1;33m         \u001b[0mbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4099\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mbm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   4101\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4102\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_consolidated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4103\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4104\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4105\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_known_consolidated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m_consolidate\u001b[1;34m(blocks)\u001b[0m\n\u001b[0;32m   5067\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_can_consolidate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_blocks\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrouper\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5068\u001b[0m         merged_blocks = _merge_blocks(list(group_blocks), dtype=dtype,\n\u001b[1;32m-> 5069\u001b[1;33m                                       _can_consolidate=_can_consolidate)\n\u001b[0m\u001b[0;32m   5070\u001b[0m         \u001b[0mnew_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerged_blocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5071\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_blocks\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m_merge_blocks\u001b[1;34m(blocks, dtype, _can_consolidate)\u001b[0m\n\u001b[0;32m   5090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5091\u001b[0m         \u001b[0margsort\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_mgr_locs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5092\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5093\u001b[0m         \u001b[0mnew_mgr_locs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5094\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist_trans = pd.read_csv('../../data/historical_transactions.csv')\n",
    "print(\"Reading data over.\")\n",
    "hist_trans_pro = pro_trans(hist_trans)\n",
    "print(\"Processing trans_agg function...\")\n",
    "hist_card_trans = trans_agg(hist_trans_pro, nunique_col=\"card_id\", prefix='hist_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_card_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_trans = pd.read_csv('../../data/historical_transactions.csv')\n",
    "print(\"Reading data over.\")\n",
    "hist_trans_pro = pro_trans(hist_trans)\n",
    "print(\"Processing trans_agg function...\")\n",
    "hist_card_trans = trans_agg(hist_trans_pro, nunique_col=\"card_id\", prefix='hist_')\n",
    "print(\"Merge df and hist_card_trans...\")\n",
    "df = pd.DataFrame()\n",
    "df[\"card_id\"] = data[\"card_id\"]\n",
    "hist_card = df.merge(hist_card_trans, on='card_id', how='left')\n",
    "del hist_trans_pro\n",
    "del hist_card_trans\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 processing new_transactions base on card_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_trans = pd.read_csv('../../data/new_merchant_transactions.csv')\n",
    "print(\"Reading data over.\")\n",
    "new_trans_pro = pro_trans(new_trans)\n",
    "print(\"Processing trans_agg function...\")\n",
    "new_card_trans = trans_agg(new_trans_pro, nunique_col=\"card_id\", prefix='new_')\n",
    "print(\"Merge df and hist_card_trans...\")\n",
    "df = pd.DataFrame()\n",
    "df[\"card_id\"] = data[\"card_id\"]\n",
    "new_card = df.merge(new_card_trans, on='card_id', how='left')\n",
    "del new_trans_pro\n",
    "del new_card_trans\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_card.to_csv(\"./feats_group/hist_card.csv\", index=False)\n",
    "new_card.to_csv(\"./feats_group/new_card.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 processing historical and new trans base on merchant_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_pro(trans, ID, prefix):\n",
    "    df = trans[[\"card_id\", ID]]\n",
    "    grouped = trans.groupby(ID)[\"installments\", \"purchase_amount\"].mean().reset_index()\n",
    "    grouped.columns = [ID, prefix+ID+\"_installments_mean\", prefix+ID+\"_purchase_amount_mean\"]\n",
    "    trans_last = df.merge(grouped, on=ID, how=\"left\")\n",
    "    \n",
    "    grouped = trans.groupby(ID)[\"installments\", \"purchase_amount\"].sum().reset_index()\n",
    "    grouped.columns = [ID, prefix+ID+\"_installments_sum\", prefix+ID+\"_purchase_amount_sum\"]\n",
    "    trans_last = trans_last.merge(grouped, on=ID, how=\"left\")\n",
    "    \n",
    "    grouped = trans.groupby(ID)[\"installments\", \"purchase_amount\"].max().reset_index()\n",
    "    grouped.columns = [ID, prefix+ID+\"_installments_max\", prefix+ID+\"_purchase_amount_max\"]\n",
    "    trans_last = trans_last.merge(grouped, on=ID, how=\"left\")\n",
    "    \n",
    "    grouped = trans.groupby(ID)[\"installments\", \"purchase_amount\"].min().reset_index()\n",
    "    grouped.columns = [ID, prefix+ID+\"_installments_min\", prefix+ID+\"_purchase_amount_min\"]\n",
    "    trans_last = trans_last.merge(grouped, on=ID, how=\"left\")\n",
    "    \n",
    "    grouped = trans.groupby(ID)[\"installments\", \"purchase_amount\"].std().reset_index()\n",
    "    grouped.columns = [ID, prefix+ID+\"_installments_std\", prefix+ID+\"_purchase_amount_std\"]\n",
    "    trans_last = trans_last.merge(grouped, on=ID, how=\"left\")\n",
    "    \n",
    "    grouped = trans.groupby(ID)[\"installments\", \"purchase_amount\"].var().reset_index()\n",
    "    grouped.columns = [ID, prefix+ID+\"_installments_var\", prefix+ID+\"_purchase_amount_var\"]\n",
    "    trans_last = trans_last.merge(grouped, on=ID, how=\"left\")\n",
    "    \n",
    "    return trans_last\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_trans_merch = id_pro(hist_trans, ID=\"merchant_id\", prefix=\"new_\")\n",
    "hist_trans_merch = hist_trans_merch.groupby(\"card_id\", as_index=False).mean()\n",
    "df = pd.DataFrame()\n",
    "df[\"card_id\"] = data[\"card_id\"]\n",
    "hist_merch = df.merge(hist_trans_merch, on=\"card_id\", how=\"left\")\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_trans_merch = id_pro(new_trans,ID=\"merchant_id\", prefix=\"new_\")\n",
    "new_trans_merch = new_trans_merch.groupby(\"card_id\", as_index=False).mean()\n",
    "df = pd.DataFrame()\n",
    "df[\"card_id\"] = data[\"card_id\"]\n",
    "new_merch = df.merge(new_trans_merch, on=\"card_id\", how=\"left\")\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 processing historical and new trans base on city_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_trans_city = id_pro(hist_trans, ID=\"city_id\", prefix=\"new_\")\n",
    "hist_trans_city = hist_trans_city.groupby(\"card_id\", as_index=False).mean()\n",
    "df = pd.DataFrame()\n",
    "df[\"card_id\"] = data[\"card_id\"]\n",
    "hist_city = df.merge(hist_trans_city, on=\"card_id\", how=\"left\")\n",
    "hist_city = hist_city.drop(\"city_id\", axis=1)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_trans_city = id_pro(new_trans, ID=\"city_id\", prefix=\"new_\")\n",
    "new_trans_city = new_trans_city.groupby(\"card_id\", as_index=False).mean()\n",
    "df = pd.DataFrame()\n",
    "df[\"card_id\"] = data[\"card_id\"]\n",
    "new_city = df.merge(new_trans_city, on=\"card_id\", how=\"left\")\n",
    "new_city = new_city.drop(\"city_id\", axis=1)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 processing historical and new trans base on merchant_category_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_trans_merchcate = id_pro(hist_trans, ID=\"merchant_category_id\", prefix=\"new_\")\n",
    "hist_trans_merchcate = hist_trans_merchcate.groupby(\"card_id\", as_index=False).mean()\n",
    "df = pd.DataFrame()\n",
    "df[\"card_id\"] = data[\"card_id\"]\n",
    "hist_merchcate = df.merge(hist_trans_merchcate, on=\"card_id\", how=\"left\")\n",
    "hist_merchcate = hist_merchcate.drop(\"merchant_category_id\", axis=1)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_trans_merchcate = id_pro(new_trans, ID=\"merchant_category_id\", prefix=\"new_\")\n",
    "new_trans_merchcate = new_trans_merchcate.groupby(\"card_id\", as_index=False).mean()\n",
    "df = pd.DataFrame()\n",
    "df[\"card_id\"] = data[\"card_id\"]\n",
    "new_merchcate = df.merge(new_trans_merchcate, on=\"card_id\", how=\"left\")\n",
    "new_merchcate = new_merchcate.drop(\"merchant_category_id\", axis=1)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6 processing historical and new trans base on state_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_trans_state = id_pro(hist_trans, ID=\"state_id\", prefix=\"new_\")\n",
    "hsit_trans_state = hist_trans_state.groupby(\"card_id\", as_index=False).mean()\n",
    "df = pd.DataFrame()\n",
    "df[\"card_id\"] = data[\"card_id\"]\n",
    "hist_state = df.merge(hist_trans_state, on=\"card_id\", how=\"left\")\n",
    "hist_state = hist_state.drop(\"state_id\", axis=1)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_trans_state = id_pro(new_trans, ID=\"state_id\", prefix=\"new_\")\n",
    "new_trans_state = new_trans_state.groupby(\"card_id\", as_index=False).mean()\n",
    "df = pd.DataFrame()\n",
    "df[\"card_id\"] = data[\"card_id\"]\n",
    "new_state = df.merge(new_trans_state, on=\"card_id\", how=\"left\")\n",
    "new_state = new_state.drop(\"state_id\", axis=1)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.7 processing historical and new trans base on subsector_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_trans_subsector = id_pro(hist_trans, ID=\"subsector_id\", prefix=\"new_\")\n",
    "hist_trans_subsector = hist_trans_subsector.groupby(\"card_id\", as_index=False).mean()\n",
    "df = pd.DataFrame()\n",
    "df[\"card_id\"] = data[\"card_id\"]\n",
    "hist_subsector = df.merge(hist_trans_subsector, on=\"card_id\", how=\"left\")\n",
    "hist_subsector = hist_subsector.drop(\"subsector_id\", axis=1)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_trans_subsector = id_pro(new_trans, ID=\"subsector_id\", prefix=\"new_\")\n",
    "new_trans_subsector = new_trans_subsector.groupby(\"card_id\", as_index=False).mean()\n",
    "df = pd.DataFrame()\n",
    "df[\"card_id\"] = data[\"card_id\"]\n",
    "new_subsector = df.merge(new_trans_subsector, on=\"card_id\", how=\"left\")\n",
    "new_subsector = new_subsector.drop(\"subsector_id\", axis=1)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_data = hist_card.merge(hist_merch, on=\"card_id\", how=\"left\") \n",
    "hist_data = hist_data.merge(hist_city, on=\"card_id\", how=\"left\")\n",
    "hist_data = hist_data.merge(hist_merchcate, on=\"card_id\", how=\"left\")\n",
    "hist_data = hist_data.merge(hist_state, on=\"card_id\", how=\"left\")\n",
    "hist_data = hist_data.merge(hist_subsector, on=\"card_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = new_card.merge(new_merch, on=\"card_id\", how=\"left\") \n",
    "new_data = new_data.merge(new_city, on=\"card_id\", how=\"left\")\n",
    "new_data = new_data.merge(new_merchcate, on=\"card_id\", how=\"left\")\n",
    "new_data = new_data.merge(new_state, on=\"card_id\", how=\"left\")\n",
    "new_data = new_data.merge(new_subsector, on=\"card_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = hist_data.merge(new_data, on=\"card_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.to_csv(\"../../data_feat/data1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
