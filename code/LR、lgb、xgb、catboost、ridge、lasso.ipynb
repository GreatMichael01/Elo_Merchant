{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/train.csv\")\n",
    "test = pd.read_csv(\"../data/test.csv\")\n",
    "X = train.drop(['first_active_month', 'card_id', 'target'], axis=1)\n",
    "y = train.target\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size=0.35, random_state=11)\n",
    "lr = LinearRegression(normalize=True)\n",
    "lr.fit(X_tr, y_tr)\n",
    "val_preds = lr.predict(X_val)\n",
    "test_preds = lr.predict(test.drop(['first_active_month', 'card_id'], axis=1))\n",
    "base_sub_df = pd.DataFrame(np.array([test.card_id, test_preds]).T, columns=['card_id', 'target'])\n",
    "base_sub_df.to_csv('../submission/sub_0_baseline.csv', index=False)\n",
    "# online=3.930"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgb+lgb+catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "%matplotlib inline\n",
    "import datetime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn import model_selection, preprocessing, metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge, RidgeCV, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/train.csv', parse_dates=['first_active_month'])\n",
    "df_test = pd.read_csv('../data/test.csv', parse_dates=['first_active_month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"month\"] = df_train[\"first_active_month\"].dt.month\n",
    "df_test[\"month\"] = df_test[\"first_active_month\"].dt.month\n",
    "\n",
    "df_train[\"year\"] = df_train[\"first_active_month\"].dt.year\n",
    "df_test[\"year\"] = df_test[\"first_active_month\"].dt.year\n",
    "\n",
    "df_train['elapsed_time'] = (datetime.date(2018, 2, 1) - df_train['first_active_month'].dt.date).dt.days\n",
    "df_test['elapsed_time'] = (datetime.date(2018, 2, 1) - df_test['first_active_month'].dt.date).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.get_dummies(df_train, columns=['feature_1', 'feature_2'])\n",
    "df_test = pd.get_dummies(df_test, columns=['feature_1', 'feature_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist = pd.read_csv('../data/historical_transactions.csv')\n",
    "df_hist = pd.get_dummies(df_hist, columns=['category_2', 'category_3'])\n",
    "df_hist['authorized_flag'] = df_hist['authorized_flag'].map({'Y': 1, 'N': 0})\n",
    "df_hist['category_1'] = df_hist['category_1'].map({'Y': 1, 'N': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_transactions(df, prefix):  \n",
    "    df.loc[:, 'purchase_date'] = pd.DatetimeIndex(df['purchase_date']).\\\n",
    "                                      astype(np.int64) * 1e-9\n",
    "    \n",
    "    agg_func = {'authorized_flag': ['sum', 'mean'],\n",
    "                'category_1': ['mean'],\n",
    "                'category_2_1.0': ['mean'],\n",
    "                'category_2_2.0': ['mean'],\n",
    "                'category_2_3.0': ['mean'],\n",
    "                'category_2_4.0': ['mean'],\n",
    "                'category_2_5.0': ['mean'],\n",
    "                'category_3_A': ['mean'],\n",
    "                'category_3_B': ['mean'],\n",
    "                'category_3_C': ['mean'],\n",
    "                'merchant_id': ['nunique'],\n",
    "                'purchase_amount': ['sum', 'mean', 'max', 'min', 'std'],\n",
    "                'installments': ['sum', 'mean', 'max', 'min', 'std'],\n",
    "                'purchase_date': [np.ptp],\n",
    "                'month_lag': ['min', 'max']\n",
    "                }\n",
    "    agg_df = df.groupby(['card_id']).agg(agg_func)\n",
    "    agg_df.columns = [prefix + '_'.join(col).strip() for col in agg_df.columns.values]\n",
    "    agg_df.reset_index(inplace=True)\n",
    "    \n",
    "    df = (df.groupby('card_id').size().reset_index(name='{}transactions_count'.format(prefix)))\n",
    "    \n",
    "    agg_df = pd.merge(df, agg_df, on='card_id', how='left')\n",
    "    \n",
    "    return agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(201917, 41) (123623, 40)\n"
     ]
    }
   ],
   "source": [
    "df_hist = aggregate_transactions(df_hist, prefix='hist_')\n",
    "df_train = pd.merge(df_train, df_hist, on='card_id',how='left')\n",
    "df_test = pd.merge(df_test, df_hist, on='card_id',how='left')\n",
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.read_csv('../data/new_merchant_transactions.csv')\n",
    "df_new = pd.get_dummies(df_new, columns=['category_2', 'category_3'])\n",
    "df_new['authorized_flag'] = df_new['authorized_flag'].map({'Y': 1, 'N': 0})\n",
    "df_new['category_1'] = df_new['category_1'].map({'Y': 1, 'N': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(201917, 67) (123623, 66)\n"
     ]
    }
   ],
   "source": [
    "df_new = aggregate_transactions(df_new, prefix='new_')\n",
    "df_train = pd.merge(df_train, df_new, on='card_id',how='left')\n",
    "df_test = pd.merge(df_test, df_new, on='card_id',how='left')\n",
    "\n",
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df_train['target']\n",
    "cols_to_drop = ['card_id', 'first_active_month', 'target']\n",
    "use_cols = [c for c in df_train.columns if c not in cols_to_drop]\n",
    "features = list(df_train[use_cols].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1、Lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 3.75147\tvalid_1's rmse: 3.81757\n",
      "[200]\ttraining's rmse: 3.69502\tvalid_1's rmse: 3.7841\n",
      "[300]\ttraining's rmse: 3.6531\tvalid_1's rmse: 3.76498\n",
      "[400]\ttraining's rmse: 3.61719\tvalid_1's rmse: 3.75078\n",
      "[500]\ttraining's rmse: 3.5871\tvalid_1's rmse: 3.74076\n",
      "[600]\ttraining's rmse: 3.56154\tvalid_1's rmse: 3.73426\n",
      "[700]\ttraining's rmse: 3.53944\tvalid_1's rmse: 3.72883\n",
      "[800]\ttraining's rmse: 3.51884\tvalid_1's rmse: 3.7248\n",
      "[900]\ttraining's rmse: 3.50013\tvalid_1's rmse: 3.72151\n",
      "[1000]\ttraining's rmse: 3.48358\tvalid_1's rmse: 3.71906\n",
      "[1100]\ttraining's rmse: 3.46722\tvalid_1's rmse: 3.71656\n",
      "[1200]\ttraining's rmse: 3.45352\tvalid_1's rmse: 3.71511\n",
      "[1300]\ttraining's rmse: 3.44004\tvalid_1's rmse: 3.71374\n",
      "[1400]\ttraining's rmse: 3.42796\tvalid_1's rmse: 3.71275\n",
      "[1500]\ttraining's rmse: 3.41636\tvalid_1's rmse: 3.7116\n",
      "[1600]\ttraining's rmse: 3.40514\tvalid_1's rmse: 3.711\n",
      "[1700]\ttraining's rmse: 3.39419\tvalid_1's rmse: 3.71011\n",
      "[1800]\ttraining's rmse: 3.38391\tvalid_1's rmse: 3.70937\n",
      "[1900]\ttraining's rmse: 3.37406\tvalid_1's rmse: 3.7088\n",
      "[2000]\ttraining's rmse: 3.36473\tvalid_1's rmse: 3.70843\n",
      "[2100]\ttraining's rmse: 3.35551\tvalid_1's rmse: 3.70792\n",
      "[2200]\ttraining's rmse: 3.34659\tvalid_1's rmse: 3.70744\n",
      "[2300]\ttraining's rmse: 3.33768\tvalid_1's rmse: 3.70713\n",
      "[2400]\ttraining's rmse: 3.32886\tvalid_1's rmse: 3.70681\n",
      "[2500]\ttraining's rmse: 3.32075\tvalid_1's rmse: 3.70663\n",
      "[2600]\ttraining's rmse: 3.31255\tvalid_1's rmse: 3.70644\n",
      "[2700]\ttraining's rmse: 3.3046\tvalid_1's rmse: 3.70624\n",
      "[2800]\ttraining's rmse: 3.29636\tvalid_1's rmse: 3.70631\n",
      "Early stopping, best iteration is:\n",
      "[2715]\ttraining's rmse: 3.30325\tvalid_1's rmse: 3.70616\n",
      "-\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 3.76895\tvalid_1's rmse: 3.74753\n",
      "[200]\ttraining's rmse: 3.70914\tvalid_1's rmse: 3.71952\n",
      "[300]\ttraining's rmse: 3.66474\tvalid_1's rmse: 3.70358\n",
      "[400]\ttraining's rmse: 3.62795\tvalid_1's rmse: 3.69187\n",
      "[500]\ttraining's rmse: 3.59737\tvalid_1's rmse: 3.68392\n",
      "[600]\ttraining's rmse: 3.57107\tvalid_1's rmse: 3.67833\n",
      "[700]\ttraining's rmse: 3.54825\tvalid_1's rmse: 3.67389\n",
      "[800]\ttraining's rmse: 3.52844\tvalid_1's rmse: 3.6707\n",
      "[900]\ttraining's rmse: 3.51022\tvalid_1's rmse: 3.6684\n",
      "[1000]\ttraining's rmse: 3.4927\tvalid_1's rmse: 3.66625\n",
      "[1100]\ttraining's rmse: 3.47709\tvalid_1's rmse: 3.66457\n",
      "[1200]\ttraining's rmse: 3.46282\tvalid_1's rmse: 3.66322\n",
      "[1300]\ttraining's rmse: 3.44874\tvalid_1's rmse: 3.66189\n",
      "[1400]\ttraining's rmse: 3.43583\tvalid_1's rmse: 3.6613\n",
      "[1500]\ttraining's rmse: 3.42451\tvalid_1's rmse: 3.66069\n",
      "[1600]\ttraining's rmse: 3.41358\tvalid_1's rmse: 3.66025\n",
      "[1700]\ttraining's rmse: 3.40305\tvalid_1's rmse: 3.65972\n",
      "[1800]\ttraining's rmse: 3.39309\tvalid_1's rmse: 3.65952\n",
      "[1900]\ttraining's rmse: 3.38327\tvalid_1's rmse: 3.65944\n",
      "[2000]\ttraining's rmse: 3.37417\tvalid_1's rmse: 3.65937\n",
      "[2100]\ttraining's rmse: 3.36523\tvalid_1's rmse: 3.65929\n",
      "Early stopping, best iteration is:\n",
      "[2023]\ttraining's rmse: 3.37194\tvalid_1's rmse: 3.65927\n",
      "-\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 3.77309\tvalid_1's rmse: 3.71884\n",
      "[200]\ttraining's rmse: 3.7142\tvalid_1's rmse: 3.68894\n",
      "[300]\ttraining's rmse: 3.67069\tvalid_1's rmse: 3.6712\n",
      "[400]\ttraining's rmse: 3.63509\tvalid_1's rmse: 3.65967\n",
      "[500]\ttraining's rmse: 3.60505\tvalid_1's rmse: 3.65125\n",
      "[600]\ttraining's rmse: 3.57952\tvalid_1's rmse: 3.64522\n",
      "[700]\ttraining's rmse: 3.55652\tvalid_1's rmse: 3.64072\n",
      "[800]\ttraining's rmse: 3.53516\tvalid_1's rmse: 3.6366\n",
      "[900]\ttraining's rmse: 3.51614\tvalid_1's rmse: 3.63397\n",
      "[1000]\ttraining's rmse: 3.4995\tvalid_1's rmse: 3.63141\n",
      "[1100]\ttraining's rmse: 3.48417\tvalid_1's rmse: 3.62975\n",
      "[1200]\ttraining's rmse: 3.46934\tvalid_1's rmse: 3.62832\n",
      "[1300]\ttraining's rmse: 3.45573\tvalid_1's rmse: 3.62668\n",
      "[1400]\ttraining's rmse: 3.44289\tvalid_1's rmse: 3.62559\n",
      "[1500]\ttraining's rmse: 3.43065\tvalid_1's rmse: 3.62503\n",
      "[1600]\ttraining's rmse: 3.4189\tvalid_1's rmse: 3.62439\n",
      "[1700]\ttraining's rmse: 3.40836\tvalid_1's rmse: 3.62388\n",
      "[1800]\ttraining's rmse: 3.39854\tvalid_1's rmse: 3.62368\n",
      "[1900]\ttraining's rmse: 3.38916\tvalid_1's rmse: 3.62349\n",
      "[2000]\ttraining's rmse: 3.37974\tvalid_1's rmse: 3.62312\n",
      "[2100]\ttraining's rmse: 3.36978\tvalid_1's rmse: 3.62297\n",
      "Early stopping, best iteration is:\n",
      "[2039]\ttraining's rmse: 3.37578\tvalid_1's rmse: 3.62291\n",
      "-\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 3.72639\tvalid_1's rmse: 3.92482\n",
      "[200]\ttraining's rmse: 3.66799\tvalid_1's rmse: 3.89333\n",
      "[300]\ttraining's rmse: 3.6249\tvalid_1's rmse: 3.87511\n",
      "[400]\ttraining's rmse: 3.58793\tvalid_1's rmse: 3.86217\n",
      "[500]\ttraining's rmse: 3.55699\tvalid_1's rmse: 3.8529\n",
      "[600]\ttraining's rmse: 3.53054\tvalid_1's rmse: 3.84583\n",
      "[700]\ttraining's rmse: 3.50802\tvalid_1's rmse: 3.84086\n",
      "[800]\ttraining's rmse: 3.48765\tvalid_1's rmse: 3.83666\n",
      "[900]\ttraining's rmse: 3.46909\tvalid_1's rmse: 3.8331\n",
      "[1000]\ttraining's rmse: 3.45223\tvalid_1's rmse: 3.83035\n",
      "[1100]\ttraining's rmse: 3.43698\tvalid_1's rmse: 3.82806\n",
      "[1200]\ttraining's rmse: 3.42227\tvalid_1's rmse: 3.8262\n",
      "[1300]\ttraining's rmse: 3.40888\tvalid_1's rmse: 3.82461\n",
      "[1400]\ttraining's rmse: 3.39603\tvalid_1's rmse: 3.82319\n",
      "[1500]\ttraining's rmse: 3.38469\tvalid_1's rmse: 3.8225\n",
      "[1600]\ttraining's rmse: 3.37374\tvalid_1's rmse: 3.82163\n",
      "[1700]\ttraining's rmse: 3.36324\tvalid_1's rmse: 3.82076\n",
      "[1800]\ttraining's rmse: 3.35333\tvalid_1's rmse: 3.82011\n",
      "[1900]\ttraining's rmse: 3.34414\tvalid_1's rmse: 3.81975\n",
      "[2000]\ttraining's rmse: 3.33521\tvalid_1's rmse: 3.81977\n",
      "[2100]\ttraining's rmse: 3.32618\tvalid_1's rmse: 3.81922\n",
      "[2200]\ttraining's rmse: 3.31735\tvalid_1's rmse: 3.81878\n",
      "[2300]\ttraining's rmse: 3.30909\tvalid_1's rmse: 3.81851\n",
      "[2400]\ttraining's rmse: 3.30082\tvalid_1's rmse: 3.81826\n",
      "[2500]\ttraining's rmse: 3.2922\tvalid_1's rmse: 3.8182\n",
      "[2600]\ttraining's rmse: 3.28371\tvalid_1's rmse: 3.81806\n",
      "Early stopping, best iteration is:\n",
      "[2560]\ttraining's rmse: 3.2871\tvalid_1's rmse: 3.81798\n",
      "-\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 3.77173\tvalid_1's rmse: 3.73191\n",
      "[200]\ttraining's rmse: 3.71392\tvalid_1's rmse: 3.70204\n",
      "[300]\ttraining's rmse: 3.67072\tvalid_1's rmse: 3.68493\n",
      "[400]\ttraining's rmse: 3.63344\tvalid_1's rmse: 3.6734\n",
      "[500]\ttraining's rmse: 3.60284\tvalid_1's rmse: 3.66561\n",
      "[600]\ttraining's rmse: 3.57587\tvalid_1's rmse: 3.66004\n",
      "[700]\ttraining's rmse: 3.55224\tvalid_1's rmse: 3.65631\n",
      "[800]\ttraining's rmse: 3.53179\tvalid_1's rmse: 3.65331\n",
      "[900]\ttraining's rmse: 3.51215\tvalid_1's rmse: 3.65024\n",
      "[1000]\ttraining's rmse: 3.49431\tvalid_1's rmse: 3.64824\n",
      "[1100]\ttraining's rmse: 3.47773\tvalid_1's rmse: 3.64665\n",
      "[1200]\ttraining's rmse: 3.4639\tvalid_1's rmse: 3.64569\n",
      "[1300]\ttraining's rmse: 3.45075\tvalid_1's rmse: 3.64465\n",
      "[1400]\ttraining's rmse: 3.43833\tvalid_1's rmse: 3.64399\n",
      "[1500]\ttraining's rmse: 3.42683\tvalid_1's rmse: 3.64375\n",
      "[1600]\ttraining's rmse: 3.41602\tvalid_1's rmse: 3.64353\n",
      "[1700]\ttraining's rmse: 3.4046\tvalid_1's rmse: 3.64332\n",
      "[1800]\ttraining's rmse: 3.39417\tvalid_1's rmse: 3.64326\n",
      "Early stopping, best iteration is:\n",
      "[1727]\ttraining's rmse: 3.40168\tvalid_1's rmse: 3.6432\n"
     ]
    }
   ],
   "source": [
    "lgb_params = {'num_leaves': 50,\n",
    "         'min_data_in_leaf': 30, \n",
    "         'objective':'regression',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.005,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1}\n",
    "\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=15)\n",
    "oof_lgb = np.zeros(len(df_train))\n",
    "predictions_lgb = np.zeros(len(df_test))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(df_train.values, target.values)):\n",
    "    print('-')\n",
    "    print(\"Fold {}\".format(fold_ + 1))\n",
    "    trn_data = lgb.Dataset(df_train.iloc[trn_idx][features], label=target.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(df_train.iloc[val_idx][features], label=target.iloc[val_idx])\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(lgb_params, trn_data, num_round, valid_sets = [trn_data, val_data], \n",
    "                    verbose_eval=100, early_stopping_rounds=100)\n",
    "    oof_lgb[val_idx] = clf.predict(df_train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "    predictions_lgb += clf.predict(df_test[features], num_iteration=clf.best_iteration) / folds.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.690564482025014"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_score = np.sqrt(mean_squared_error(target, oof_lgb))\n",
    "validation_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = pd.DataFrame({\"card_id\": df_test[\"card_id\"].values})\n",
    "df_submission[\"target\"] = predictions_lgb\n",
    "df_submission.to_csv(\"../submission/lgb12131605.csv\", index=False)\n",
    "\n",
    "# online=3.738"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2、xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Fold 1\n",
      "xgb 0--------------------------------------------------\n",
      "[0]\ttrain-rmse:3.94008\tvalid-rmse:3.98681\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 50 rounds.\n",
      "[200]\ttrain-rmse:3.49157\tvalid-rmse:3.78322\n",
      "[400]\ttrain-rmse:3.2684\tvalid-rmse:3.73671\n",
      "[600]\ttrain-rmse:3.12562\tvalid-rmse:3.72128\n",
      "[800]\ttrain-rmse:3.03269\tvalid-rmse:3.71554\n",
      "[1000]\ttrain-rmse:2.96113\tvalid-rmse:3.71264\n",
      "[1200]\ttrain-rmse:2.89615\tvalid-rmse:3.71126\n",
      "Stopping. Best iteration:\n",
      "[1288]\ttrain-rmse:2.86982\tvalid-rmse:3.71085\n",
      "\n",
      "-\n",
      "Fold 2\n",
      "xgb 1--------------------------------------------------\n",
      "[0]\ttrain-rmse:3.96013\tvalid-rmse:3.90615\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 50 rounds.\n",
      "[200]\ttrain-rmse:3.49784\tvalid-rmse:3.71616\n",
      "[400]\ttrain-rmse:3.26637\tvalid-rmse:3.67674\n",
      "[600]\ttrain-rmse:3.11642\tvalid-rmse:3.66414\n",
      "[800]\ttrain-rmse:3.01862\tvalid-rmse:3.66016\n",
      "[1000]\ttrain-rmse:2.94111\tvalid-rmse:3.65837\n",
      "Stopping. Best iteration:\n",
      "[1035]\ttrain-rmse:2.92989\tvalid-rmse:3.6581\n",
      "\n",
      "-\n",
      "Fold 3\n",
      "xgb 2--------------------------------------------------\n",
      "[0]\ttrain-rmse:3.96748\tvalid-rmse:3.87646\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 50 rounds.\n",
      "[200]\ttrain-rmse:3.51041\tvalid-rmse:3.68331\n",
      "[400]\ttrain-rmse:3.28604\tvalid-rmse:3.64436\n",
      "[600]\ttrain-rmse:3.1428\tvalid-rmse:3.63252\n",
      "[800]\ttrain-rmse:3.04848\tvalid-rmse:3.6288\n",
      "Stopping. Best iteration:\n",
      "[912]\ttrain-rmse:3.00575\tvalid-rmse:3.62796\n",
      "\n",
      "-\n",
      "Fold 4\n",
      "xgb 3--------------------------------------------------\n",
      "[0]\ttrain-rmse:3.91351\tvalid-rmse:4.09137\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 50 rounds.\n",
      "[200]\ttrain-rmse:3.46091\tvalid-rmse:3.89387\n",
      "[400]\ttrain-rmse:3.23807\tvalid-rmse:3.8479\n",
      "[600]\ttrain-rmse:3.08978\tvalid-rmse:3.83246\n",
      "[800]\ttrain-rmse:2.99342\tvalid-rmse:3.82724\n",
      "[1000]\ttrain-rmse:2.92229\tvalid-rmse:3.82486\n",
      "[1200]\ttrain-rmse:2.85519\tvalid-rmse:3.82344\n",
      "Stopping. Best iteration:\n",
      "[1206]\ttrain-rmse:2.85376\tvalid-rmse:3.82336\n",
      "\n",
      "-\n",
      "Fold 5\n",
      "xgb 4--------------------------------------------------\n",
      "[0]\ttrain-rmse:3.96461\tvalid-rmse:3.88877\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 50 rounds.\n",
      "[200]\ttrain-rmse:3.51186\tvalid-rmse:3.69783\n",
      "[400]\ttrain-rmse:3.28439\tvalid-rmse:3.65972\n",
      "[600]\ttrain-rmse:3.13661\tvalid-rmse:3.65014\n",
      "[800]\ttrain-rmse:3.0386\tvalid-rmse:3.64702\n",
      "[1000]\ttrain-rmse:2.96406\tvalid-rmse:3.64571\n",
      "Stopping. Best iteration:\n",
      "[1065]\ttrain-rmse:2.94289\tvalid-rmse:3.64544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {'eta': 0.005, \n",
    "              'max_depth': 10, \n",
    "              'subsample': 0.8, \n",
    "              'colsample_bytree': 0.8, \n",
    "              'objective': 'reg:linear', \n",
    "              'eval_metric': 'rmse', \n",
    "              'silent': True}\n",
    "\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=15)\n",
    "oof_xgb = np.zeros(len(df_train))\n",
    "predictions_xgb = np.zeros(len(df_test))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(df_train.values, target.values)):\n",
    "    print('-')\n",
    "    print(\"Fold {}\".format(fold_ + 1))\n",
    "    trn_data = xgb.DMatrix(data=df_train.iloc[trn_idx][features], label=target.iloc[trn_idx])\n",
    "    val_data = xgb.DMatrix(data=df_train.iloc[val_idx][features], label=target.iloc[val_idx])\n",
    "    watchlist = [(trn_data, 'train'), (val_data, 'valid')]\n",
    "    print(\"xgb \" + str(fold_) + \"-\" * 50)\n",
    "    num_round = 10000\n",
    "    xgb_model = xgb.train(xgb_params, trn_data, num_round, watchlist, \n",
    "                          early_stopping_rounds=50, verbose_eval=200)\n",
    "    oof_xgb[val_idx] = xgb_model.predict(xgb.DMatrix(df_train.iloc[val_idx][features]), \n",
    "                                         ntree_limit=xgb_model.best_ntree_limit+50)\n",
    "\n",
    "    predictions_xgb += xgb_model.predict(xgb.DMatrix(df_test[features]), \n",
    "                                         ntree_limit=xgb_model.best_ntree_limit+50) / folds.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.693962942857355"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_score = np.sqrt(mean_squared_error(target, oof_xgb))\n",
    "validation_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = pd.DataFrame({\"card_id\": df_test[\"card_id\"].values})\n",
    "df_submission[\"target\"] = predictions_xgb\n",
    "df_submission.to_csv(\"../submission/xgb12131646.csv\", index=False)\n",
    "\n",
    "# online=3.745"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3、catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_\n",
      "Fold 1\n",
      "cb 0__________________________________________________\n",
      "0:\tlearn: 3.8605352\ttest: 3.8605352\ttest1: 3.9041308\tbest: 3.9041308 (0)\ttotal: 192ms\tremaining: 32m 2s\n",
      "400:\tlearn: 3.6699645\ttest: 3.6699645\ttest1: 3.7536176\tbest: 3.7536176 (400)\ttotal: 34.7s\tremaining: 13m 49s\n",
      "800:\tlearn: 3.6133553\ttest: 3.6133553\ttest1: 3.7328984\tbest: 3.7328984 (800)\ttotal: 1m 6s\tremaining: 12m 43s\n",
      "1200:\tlearn: 3.5730400\ttest: 3.5730400\ttest1: 3.7231023\tbest: 3.7231023 (1200)\ttotal: 1m 37s\tremaining: 11m 54s\n",
      "1600:\tlearn: 3.5371259\ttest: 3.5371259\ttest1: 3.7176282\tbest: 3.7176282 (1600)\ttotal: 2m 8s\tremaining: 11m 16s\n",
      "2000:\tlearn: 3.5054497\ttest: 3.5054497\ttest1: 3.7141400\tbest: 3.7141400 (2000)\ttotal: 2m 39s\tremaining: 10m 37s\n",
      "2400:\tlearn: 3.4755359\ttest: 3.4755359\ttest1: 3.7118845\tbest: 3.7118845 (2400)\ttotal: 3m 10s\tremaining: 10m 2s\n",
      "2800:\tlearn: 3.4473954\ttest: 3.4473954\ttest1: 3.7103322\tbest: 3.7103322 (2800)\ttotal: 3m 40s\tremaining: 9m 27s\n",
      "3200:\tlearn: 3.4197028\ttest: 3.4197028\ttest1: 3.7090015\tbest: 3.7090015 (3200)\ttotal: 4m 11s\tremaining: 8m 54s\n",
      "3600:\tlearn: 3.3937226\ttest: 3.3937226\ttest1: 3.7081516\tbest: 3.7081516 (3600)\ttotal: 4m 42s\tremaining: 8m 22s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 3.70756102\n",
      "bestIteration = 3931\n",
      "\n",
      "Shrink model to first 3932 iterations.\n",
      "_\n",
      "Fold 2\n",
      "cb 1__________________________________________________\n",
      "0:\tlearn: 3.8804412\ttest: 3.8804412\ttest1: 3.8242180\tbest: 3.8242180 (0)\ttotal: 97.8ms\tremaining: 16m 17s\n",
      "400:\tlearn: 3.6835819\ttest: 3.6835819\ttest1: 3.6886478\tbest: 3.6886478 (400)\ttotal: 34.2s\tremaining: 13m 38s\n",
      "800:\tlearn: 3.6225520\ttest: 3.6225520\ttest1: 3.6719126\tbest: 3.6719126 (800)\ttotal: 1m 6s\tremaining: 12m 46s\n",
      "1200:\tlearn: 3.5802853\ttest: 3.5802853\ttest1: 3.6647224\tbest: 3.6647224 (1200)\ttotal: 1m 38s\tremaining: 12m\n",
      "1600:\tlearn: 3.5460483\ttest: 3.5460483\ttest1: 3.6609591\tbest: 3.6609591 (1600)\ttotal: 2m 10s\tremaining: 11m 26s\n",
      "2000:\tlearn: 3.5134741\ttest: 3.5134741\ttest1: 3.6589964\tbest: 3.6589780 (1986)\ttotal: 2m 43s\tremaining: 10m 51s\n",
      "2400:\tlearn: 3.4836411\ttest: 3.4836411\ttest1: 3.6579333\tbest: 3.6579309 (2399)\ttotal: 3m 14s\tremaining: 10m 14s\n",
      "2800:\tlearn: 3.4551291\ttest: 3.4551291\ttest1: 3.6569507\tbest: 3.6569385 (2793)\ttotal: 3m 45s\tremaining: 9m 39s\n",
      "3200:\tlearn: 3.4288746\ttest: 3.4288746\ttest1: 3.6562301\tbest: 3.6562137 (3196)\ttotal: 4m 16s\tremaining: 9m 4s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 3.655735817\n",
      "bestIteration = 3497\n",
      "\n",
      "Shrink model to first 3498 iterations.\n",
      "_\n",
      "Fold 3\n",
      "cb 2__________________________________________________\n",
      "0:\tlearn: 3.8871617\ttest: 3.8871617\ttest1: 3.7969391\tbest: 3.7969391 (0)\ttotal: 98.4ms\tremaining: 16m 23s\n",
      "400:\tlearn: 3.6910218\ttest: 3.6910218\ttest1: 3.6619929\tbest: 3.6619929 (400)\ttotal: 34.8s\tremaining: 13m 53s\n",
      "800:\tlearn: 3.6313617\ttest: 3.6313617\ttest1: 3.6429147\tbest: 3.6429147 (800)\ttotal: 1m 7s\tremaining: 12m 59s\n",
      "1200:\tlearn: 3.5921200\ttest: 3.5921200\ttest1: 3.6342589\tbest: 3.6342589 (1200)\ttotal: 1m 39s\tremaining: 12m 11s\n",
      "1600:\tlearn: 3.5589419\ttest: 3.5589419\ttest1: 3.6308664\tbest: 3.6308664 (1600)\ttotal: 2m 11s\tremaining: 11m 29s\n",
      "2000:\tlearn: 3.5277962\ttest: 3.5277962\ttest1: 3.6284477\tbest: 3.6284258 (1998)\ttotal: 2m 43s\tremaining: 10m 51s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 3.628253304\n",
      "bestIteration = 2055\n",
      "\n",
      "Shrink model to first 2056 iterations.\n",
      "_\n",
      "Fold 4\n",
      "cb 3__________________________________________________\n",
      "0:\tlearn: 3.8338323\ttest: 3.8338323\ttest1: 4.0080530\tbest: 4.0080530 (0)\ttotal: 100ms\tremaining: 16m 40s\n",
      "400:\tlearn: 3.6413777\ttest: 3.6413777\ttest1: 3.8688681\tbest: 3.8688681 (400)\ttotal: 35.5s\tremaining: 14m 9s\n",
      "800:\tlearn: 3.5797699\ttest: 3.5797699\ttest1: 3.8476814\tbest: 3.8476814 (800)\ttotal: 1m 8s\tremaining: 13m 9s\n",
      "1200:\tlearn: 3.5374555\ttest: 3.5374555\ttest1: 3.8383455\tbest: 3.8383455 (1200)\ttotal: 1m 42s\tremaining: 12m 29s\n",
      "1600:\tlearn: 3.5030737\ttest: 3.5030737\ttest1: 3.8335004\tbest: 3.8335004 (1600)\ttotal: 2m 14s\tremaining: 11m 48s\n",
      "2000:\tlearn: 3.4715137\ttest: 3.4715137\ttest1: 3.8303931\tbest: 3.8303931 (2000)\ttotal: 2m 46s\tremaining: 11m 6s\n",
      "2400:\tlearn: 3.4431108\ttest: 3.4431108\ttest1: 3.8282950\tbest: 3.8282930 (2395)\ttotal: 3m 18s\tremaining: 10m 28s\n",
      "2800:\tlearn: 3.4161820\ttest: 3.4161820\ttest1: 3.8268961\tbest: 3.8268961 (2800)\ttotal: 3m 49s\tremaining: 9m 50s\n",
      "3200:\tlearn: 3.3899799\ttest: 3.3899799\ttest1: 3.8253506\tbest: 3.8253502 (3199)\ttotal: 4m 22s\tremaining: 9m 17s\n",
      "3600:\tlearn: 3.3656522\ttest: 3.3656522\ttest1: 3.8246220\tbest: 3.8245917 (3581)\ttotal: 4m 55s\tremaining: 8m 45s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 3.824519602\n",
      "bestIteration = 3619\n",
      "\n",
      "Shrink model to first 3620 iterations.\n",
      "_\n",
      "Fold 5\n",
      "cb 4__________________________________________________\n",
      "0:\tlearn: 3.8840126\ttest: 3.8840126\ttest1: 3.8096526\tbest: 3.8096526 (0)\ttotal: 98.1ms\tremaining: 16m 20s\n",
      "400:\tlearn: 3.6861749\ttest: 3.6861749\ttest1: 3.6734431\tbest: 3.6734431 (400)\ttotal: 36.2s\tremaining: 14m 25s\n",
      "800:\tlearn: 3.6237420\ttest: 3.6237420\ttest1: 3.6564155\tbest: 3.6564155 (800)\ttotal: 1m 10s\tremaining: 13m 24s\n",
      "1200:\tlearn: 3.5790722\ttest: 3.5790722\ttest1: 3.6498681\tbest: 3.6498653 (1199)\ttotal: 1m 42s\tremaining: 12m 33s\n",
      "1600:\tlearn: 3.5424930\ttest: 3.5424930\ttest1: 3.6467373\tbest: 3.6467327 (1593)\ttotal: 2m 15s\tremaining: 11m 50s\n",
      "2000:\tlearn: 3.5103602\ttest: 3.5103602\ttest1: 3.6449236\tbest: 3.6449175 (1998)\ttotal: 2m 47s\tremaining: 11m 9s\n",
      "2400:\tlearn: 3.4813412\ttest: 3.4813412\ttest1: 3.6438731\tbest: 3.6438731 (2400)\ttotal: 3m 19s\tremaining: 10m 31s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 3.643592573\n",
      "bestIteration = 2503\n",
      "\n",
      "Shrink model to first 2504 iterations.\n"
     ]
    }
   ],
   "source": [
    "kfolds = KFold(n_splits=5, shuffle=True, random_state=15)\n",
    "oof_cb = np.zeros(len(df_train))\n",
    "predictions_cb = np.zeros(len(df_test))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(df_train.values, target.values)):\n",
    "    print(\"_\")\n",
    "    print(\"Fold {}\".format(fold_ + 1))\n",
    "    X_train, y_train = df_train[features].iloc[trn_idx], target.iloc[trn_idx]\n",
    "    X_valid, y_valid = df_train[features].iloc[val_idx], target.iloc[val_idx]\n",
    "    print(\"cb \" + str(fold_) + \"_\" * 50)\n",
    "    \n",
    "    # CatBoost Regressor estimator\n",
    "    model = cb.CatBoostRegressor(learning_rate = 0.005,\n",
    "        iterations = 10000,\n",
    "        eval_metric = 'RMSE',\n",
    "        allow_writing_files = False,\n",
    "        od_type = 'Iter',\n",
    "        bagging_temperature = 0.2,\n",
    "        depth = 10,\n",
    "        od_wait = 20,\n",
    "        silent = True)\n",
    "    \n",
    "            \n",
    "    # Fit\n",
    "    model.fit(X_train, y_train,\n",
    "              eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "              early_stopping_rounds=50,\n",
    "              verbose_eval=400)\n",
    "    \n",
    "    oof_cb[val_idx] = model.predict(X_valid)\n",
    "    predictions_cb += model.predict(df_test[features]) / kfolds.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6926237436123257"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_score = np.sqrt(mean_squared_error(target, oof_cb))\n",
    "validation_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = pd.DataFrame({\"card_id\": df_test[\"card_id\"].values})\n",
    "df_submission[\"target\"] = predictions_cb\n",
    "df_submission.to_csv(\"../submission/cb12131722.csv\", index=False)\n",
    "\n",
    "# online=3.751"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4、Ridge模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold no.1\n",
      "fold no.2\n",
      "fold no.3\n",
      "fold no.4\n",
      "fold no.5\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=15)\n",
    "oof_ridge = np.zeros(len(df_train))\n",
    "predictions_ridge = np.zeros(len(df_test))\n",
    "\n",
    "tst_data = df_test.copy()\n",
    "tst_data.fillna((tst_data.mean()), inplace=True)\n",
    "\n",
    "tst_data = tst_data[features].values\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(df_train, target)):\n",
    "    print(\"fold no.{}\".format(fold_+1))\n",
    "    trn_data, trn_y = df_train.iloc[trn_idx][features], target.iloc[trn_idx].values\n",
    "    val_data, val_y = df_train.iloc[val_idx][features], target.iloc[val_idx].values\n",
    "    \n",
    "    trn_data.fillna((trn_data.mean()), inplace=True)\n",
    "    val_data.fillna((val_data.mean()), inplace=True)\n",
    "    \n",
    "    trn_data = trn_data.values\n",
    "    val_data = val_data.values\n",
    "\n",
    "    clf = Ridge(alpha=100)\n",
    "    clf.fit(trn_data, trn_y)\n",
    "    \n",
    "    oof_ridge[val_idx] = clf.predict(val_data)\n",
    "    predictions_ridge += clf.predict(tst_data) / folds.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8285953928376797"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_score = np.sqrt(mean_squared_error(target, oof_ridge))\n",
    "validation_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = pd.DataFrame({\"card_id\": df_test[\"card_id\"].values})\n",
    "df_submission[\"target\"] = predictions_ridge\n",
    "df_submission.to_csv(\"../submission/ridge12131724.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5、Lasso模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold no.1\n",
      "fold no.2\n",
      "fold no.3\n",
      "fold no.4\n",
      "fold no.5\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=15)\n",
    "oof_lasso = np.zeros(len(df_train))\n",
    "predictions_lasso = np.zeros(len(df_test))\n",
    "\n",
    "tst_data = df_test.copy()\n",
    "tst_data.fillna((tst_data.mean()), inplace=True)\n",
    "\n",
    "tst_data = tst_data[features].values\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(df_train, target)):\n",
    "    print(\"fold no.{}\".format(fold_+1))\n",
    "    trn_data, trn_y = df_train.iloc[trn_idx][features], target.iloc[trn_idx].values\n",
    "    val_data, val_y = df_train.iloc[val_idx][features], target.iloc[val_idx].values\n",
    "    \n",
    "    trn_data.fillna((trn_data.mean()), inplace=True)\n",
    "    val_data.fillna((val_data.mean()), inplace=True)\n",
    "    \n",
    "    trn_data = trn_data.values\n",
    "    val_data = val_data.values\n",
    "\n",
    "    clf = Lasso(alpha=100)\n",
    "    clf.fit(trn_data, trn_y)\n",
    "    \n",
    "    oof_ridge[val_idx] = clf.predict(val_data)\n",
    "    predictions_lasso += clf.predict(tst_data) / folds.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8705589161316296"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_score = np.sqrt(mean_squared_error(target, oof_lasso))\n",
    "validation_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = pd.DataFrame({\"card_id\": df_test[\"card_id\"].values})\n",
    "df_submission[\"target\"] = predictions_lasso\n",
    "df_submission.to_csv(\"../submission/lasso12131726.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6、stacking融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold no. 1\n",
      "fold no. 2\n",
      "fold no. 3\n",
      "fold no. 4\n",
      "fold no. 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.686560466875316"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stack = np.vstack([oof_cb, oof_lgb, oof_xgb, oof_ridge, oof_lasso]).transpose()\n",
    "test_stack = np.vstack([predictions_cb, predictions_lgb, predictions_xgb, predictions_ridge, predictions_lasso]).transpose()\n",
    "\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=15)\n",
    "oof = np.zeros(train_stack.shape[0])\n",
    "predictions = np.zeros(test_stack.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_stack, target)):\n",
    "    print(\"fold no. {}\".format(fold_ + 1))\n",
    "    trn_data, trn_y = train_stack[trn_idx], target.iloc[trn_idx].values\n",
    "    val_data, val_y = train_stack[val_idx], target.iloc[val_idx].values\n",
    "\n",
    "    clf = Ridge(alpha=500)\n",
    "    clf.fit(trn_data, trn_y)\n",
    "    \n",
    "    oof[val_idx] = clf.predict(val_data)\n",
    "    predictions += clf.predict(test_stack) / folds.n_splits\n",
    "\n",
    "\n",
    "np.sqrt(mean_squared_error(target, oof))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = pd.DataFrame({\"card_id\": df_test[\"card_id\"].values})\n",
    "df_submission[\"target\"] = predictions\n",
    "df_submission.to_csv(\"../submission/stacking12131728.csv\", index=False)\n",
    "# online=3.739"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
